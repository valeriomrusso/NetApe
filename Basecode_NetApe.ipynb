{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTILS & ALGORITHMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from typing import Tuple, List\n",
    "\n",
    "def get_player_location(game_map: np.ndarray, symbol : str = \"@\") -> Tuple[int, int]:\n",
    "    x, y = np.where(game_map == ord(symbol))\n",
    "    return (x[0], y[0])\n",
    "\n",
    "def get_target_location(game_map: np.ndarray, symbol : str = \">\") -> Tuple[int, int]:\n",
    "    x, y = np.where(game_map == ord(symbol))\n",
    "    return (x[0], y[0])\n",
    "\n",
    "def is_wall(position_element: int) -> bool:\n",
    "    obstacles = \"|- \"\n",
    "    return chr(position_element) in obstacles\n",
    "\n",
    "def get_valid_moves(game_map: np.ndarray, current_position: Tuple[int, int]) -> List[Tuple[int, int]]:\n",
    "    x_limit, y_limit = game_map.shape\n",
    "    valid = []\n",
    "    x, y = current_position    \n",
    "    # North\n",
    "    if y - 1 > 0 and not is_wall(game_map[x, y-1]):\n",
    "        valid.append((x, y-1)) \n",
    "    # East\n",
    "    if x + 1 < x_limit and not is_wall(game_map[x+1, y]):\n",
    "        valid.append((x+1, y)) \n",
    "    # South\n",
    "    if y + 1 < y_limit and not is_wall(game_map[x, y+1]):\n",
    "        valid.append((x, y+1)) \n",
    "    # West\n",
    "    if x - 1 > 0 and not is_wall(game_map[x-1, y]):\n",
    "        valid.append((x-1, y))\n",
    "\n",
    "    return valid\n",
    "\n",
    "def actions_from_path(start: Tuple[int, int], path: List[Tuple[int, int]]) -> List[int]:\n",
    "    action_map = {\n",
    "        \"N\": 0,\n",
    "        \"E\": 1,\n",
    "        \"S\": 2,\n",
    "        \"W\": 3\n",
    "    }\n",
    "    actions = []\n",
    "    x_s, y_s = start\n",
    "    for (x, y) in path:\n",
    "        if x_s == x:\n",
    "            if y_s > y:\n",
    "                actions.append(action_map[\"W\"])\n",
    "            else: actions.append(action_map[\"E\"])\n",
    "        elif y_s == y:\n",
    "            if x_s > x:\n",
    "                actions.append(action_map[\"N\"])\n",
    "            else: actions.append(action_map[\"S\"])\n",
    "        else:\n",
    "            raise Exception(\"x and y can't change at the same time. oblique moves not allowed!\")\n",
    "        x_s = x\n",
    "        y_s = y\n",
    "    \n",
    "    return actions\n",
    "\n",
    "def euclidean_distance(point1: Tuple[int, int], point2: Tuple[int, int]) -> float:\n",
    "    x1, y1 = point1\n",
    "    x2, y2 = point2\n",
    "    return math.sqrt((x1 - x2)**2 + (y1 - y2)**2)\n",
    "\n",
    "\n",
    "def manhattan_distance(point1: Tuple[int, int], point2: Tuple[int, int]) -> int:\n",
    "    x1, y1 = point1\n",
    "    x2, y2 = point2\n",
    "    return abs(x1 - x2) + abs(y1 - y2)\n",
    "\n",
    "def monster_penalty(game_map: np.ndarray, position: Tuple[int, int], monsters: List[Tuple[int, int]], max_penalty: int = 10) -> int:\n",
    "    penalty = 0\n",
    "    for monster in monsters:\n",
    "        dist = manhattan_distance(position, monster)\n",
    "        if dist == 0:\n",
    "            return float('inf')  # Evita i nodi occupati dai mostri\n",
    "        penalty += max(0, max_penalty - dist)\n",
    "    return penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from collections import deque\n",
    "from queue import PriorityQueue\n",
    "\n",
    "from typing import Tuple, List\n",
    "import heapq\n",
    "\n",
    "def build_path(parent: dict, target: Tuple[int, int]) -> List[Tuple[int, int]]:\n",
    "    path = []\n",
    "    while target is not None:\n",
    "        path.append(target)\n",
    "        target = parent[target]\n",
    "    path.reverse()\n",
    "    return path\n",
    "\n",
    "def bfs(game_map: np.ndarray, start: Tuple[int, int], target: Tuple[int, int]) -> List[Tuple[int, int]]:\n",
    "    # Create a queue for BFS and mark the start node as visited\n",
    "    queue = deque()\n",
    "    visited = set()\n",
    "    queue.append(start)\n",
    "    visited.add(start)\n",
    "\n",
    "    # Create a dictionary to keep track of the parent node for each node in the path\n",
    "    parent = {start: None}\n",
    "\n",
    "    while queue:\n",
    "        # Dequeue a vertex from the queue\n",
    "        current = queue.popleft()\n",
    "\n",
    "        # Check if the target node has been reached\n",
    "        if current == target:\n",
    "            print(\"Target found!\")\n",
    "            path = build_path(parent, target)\n",
    "            return path\n",
    "\n",
    "        # Visit all adjacent neighbors of the dequeued vertex\n",
    "        for neighbor in get_valid_moves(game_map, current):\n",
    "            if neighbor not in visited:\n",
    "                queue.append(neighbor)\n",
    "                visited.add(neighbor)\n",
    "                parent[neighbor] = current\n",
    "\n",
    "    print(\"Target node not found!\")\n",
    "    return None\n",
    "\n",
    "# ---------------------------------------------\n",
    "\n",
    "def a_star(game_map: np.ndarray, start: Tuple[int, int], target: Tuple[int, int], h: callable) -> List[Tuple[int, int]]:\n",
    "    # initialize open and close list\n",
    "    open_list = PriorityQueue()\n",
    "    close_list = []\n",
    "    # additional dict which maintains the nodes in the open list for an easier access and check\n",
    "    support_list = {}\n",
    "\n",
    "    starting_state_g = 0\n",
    "    starting_state_h = h(start, target)\n",
    "    starting_state_f = starting_state_g + starting_state_h\n",
    "\n",
    "    open_list.put((starting_state_f, (start, starting_state_g)))\n",
    "    support_list[start] = starting_state_g\n",
    "    parent = {start: None}\n",
    "\n",
    "    while not open_list.empty():\n",
    "        # get the node with lowest f\n",
    "        _, (current, current_cost) = open_list.get()\n",
    "        # add the node to the close list\n",
    "        close_list.append(current)\n",
    "\n",
    "        if current == target:\n",
    "            print(\"Target found!\")\n",
    "            path = build_path(parent, target)\n",
    "            return path\n",
    "\n",
    "        for neighbor in get_valid_moves(game_map, current):\n",
    "            # check if neighbor in close list, if so continue\n",
    "            if neighbor in close_list:\n",
    "                continue\n",
    "            # compute neighbor g, h and f values\n",
    "            neighbor_g = 1 + current_cost\n",
    "            neighbor_h = h(neighbor, target)\n",
    "            neighbor_f = neighbor_g + neighbor_h\n",
    "            parent[neighbor] = current\n",
    "            neighbor_entry = (neighbor_f, (neighbor, neighbor_g))\n",
    "            # if neighbor in open_list\n",
    "            if neighbor in support_list.keys():\n",
    "                # if neighbor_g is greater or equal to the one in the open list, continue\n",
    "                if neighbor_g >= support_list[neighbor]:\n",
    "                    continue\n",
    "            \n",
    "            # add neighbor to open list and update support_list\n",
    "            open_list.put(neighbor_entry)\n",
    "            support_list[neighbor] = neighbor_g\n",
    "\n",
    "    print(\"Target node not found!\")\n",
    "    return None\n",
    "\n",
    "# ----------------------------------------\n",
    "\n",
    "def greedy(game_map: np.ndarray, start: Tuple[int, int], target: Tuple[int, int], h: callable) -> List[Tuple[int, int]]:\n",
    "    open_list = PriorityQueue()\n",
    "    open_list.put((h(start, target), start))\n",
    "\n",
    "    visited = set()\n",
    "    parent = {start: None}\n",
    "\n",
    "    while not open_list.empty():\n",
    "        _, current = open_list.get()\n",
    "\n",
    "        if current == target:\n",
    "            print(\"Target found!\")\n",
    "            return build_path(parent, target)\n",
    "\n",
    "        visited.add(current)\n",
    "\n",
    "        for neighbor in get_valid_moves(game_map, current):\n",
    "            if neighbor not in visited:\n",
    "                open_list.put((h(neighbor, target), neighbor))\n",
    "                visited.add(neighbor)\n",
    "                parent[neighbor] = current\n",
    "\n",
    "    print(\"Target node not found!\")\n",
    "    return None\n",
    "\n",
    "# ----------------------------------------\n",
    "\n",
    "def dfs(game_map: np.ndarray, start: Tuple[int, int], target: Tuple[int, int]) -> List[Tuple[int, int]]:\n",
    "    stack = []\n",
    "    visited = set()\n",
    "    stack.append(start)\n",
    "    visited.add(start)\n",
    "\n",
    "    parent = {start: None}\n",
    "\n",
    "    while stack:\n",
    "        current = stack.pop()\n",
    "\n",
    "        if current == target:\n",
    "            print(\"Target found!\")\n",
    "            return build_path(parent, target)\n",
    "\n",
    "        for neighbor in get_valid_moves(game_map, current):\n",
    "            if neighbor not in visited:\n",
    "                stack.append(neighbor)\n",
    "                visited.add(neighbor)\n",
    "                parent[neighbor] = current\n",
    "\n",
    "    print(\"Target node not found!\")\n",
    "    return None\n",
    "\n",
    "# ----------------------------------------\n",
    "\n",
    "def iddfs(game_map: np.ndarray, start: Tuple[int, int], target: Tuple[int, int], max_depth: int) -> List[Tuple[int, int]]:\n",
    "    for depth in range(max_depth + 1):\n",
    "        print(f\"Exploring depth: {depth}\")\n",
    "        path = []\n",
    "        visited = set()\n",
    "        if dfs_limited(game_map, start, target, depth, path, visited):\n",
    "            path.reverse()  # Reverse to get the path from start to target\n",
    "            return path\n",
    "    print(\"Target node not found!\")\n",
    "    return None\n",
    "\n",
    "def dfs_limited(game_map: np.ndarray, current: Tuple[int, int], target: Tuple[int, int], depth: int,\n",
    "                path: List[Tuple[int, int]], visited: set) -> bool:\n",
    "    if current == target:\n",
    "        path.append(current)\n",
    "        return True\n",
    "    if depth <= 0:\n",
    "        return False\n",
    "\n",
    "    visited.add(current)\n",
    "    for neighbor in get_valid_moves(game_map, current):\n",
    "        if neighbor not in visited:\n",
    "            if dfs_limited(game_map, neighbor, target, depth - 1, path, visited):\n",
    "                path.append(current)\n",
    "                return True\n",
    "    visited.remove(current)\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "\n",
    "def beam_search(game_map: np.ndarray, start: Tuple[int, int], target: Tuple[int, int], h: callable, beam_width: int) -> List[Tuple[int, int]]:\n",
    "    current_nodes = [start]\n",
    "    parent = {start: None}\n",
    "    visited = set()\n",
    "\n",
    "    while current_nodes:\n",
    "        neighbors = []\n",
    "\n",
    "        for node in current_nodes:\n",
    "            if node == target:\n",
    "                print(\"Target found!\")\n",
    "                return build_path(parent, target)\n",
    "\n",
    "            visited.add(node)\n",
    "\n",
    "            for neighbor in get_valid_moves(game_map, node):\n",
    "                if neighbor not in visited:\n",
    "                    neighbors.append((h(neighbor, target), neighbor))\n",
    "                    parent[neighbor] = node\n",
    "\n",
    "        if not neighbors:\n",
    "            break\n",
    "\n",
    "        neighbors.sort()\n",
    "        current_nodes = [node for _, node in neighbors[:beam_width]]\n",
    "\n",
    "    print(\"Target node not found!\")\n",
    "    return None\n",
    "\n",
    "# ----------------------------------------\n",
    "\n",
    "def theta_star(game_map: np.ndarray, start: Tuple[int, int], target: Tuple[int, int], h: callable) -> List[Tuple[int, int]]:\n",
    "    open_list = []\n",
    "    heapq.heappush(open_list, (0, start))\n",
    "    came_from = {start: None}\n",
    "    g_score = {start: 0}\n",
    "    visited = set()\n",
    "\n",
    "    while open_list:\n",
    "        _, current = heapq.heappop(open_list)\n",
    "        visited.add(current)\n",
    "\n",
    "        if current == target:\n",
    "            return build_path(came_from, target)\n",
    "\n",
    "        for neighbor in get_valid_moves(game_map, current):\n",
    "            if neighbor in visited:\n",
    "                continue\n",
    "\n",
    "            parent = came_from.get(current, None)\n",
    "            if parent is None:\n",
    "                parent = current\n",
    "\n",
    "            if line_of_sight(game_map, parent, neighbor):\n",
    "                tentative_g_score = g_score[parent] +  euclidean_distance(parent, neighbor)\n",
    "            else:\n",
    "                tentative_g_score = g_score[current] + euclidean_distance(current, neighbor)\n",
    "\n",
    "            if neighbor not in g_score or tentative_g_score < g_score[neighbor]:\n",
    "                came_from[neighbor] = current\n",
    "                g_score[neighbor] = tentative_g_score\n",
    "                f_score = tentative_g_score + h(neighbor, target)\n",
    "                heapq.heappush(open_list, (f_score, neighbor))\n",
    "\n",
    "    print(\"Target node not found!\")\n",
    "    return None\n",
    "\n",
    "def line_of_sight(game_map: np.ndarray, start: Tuple[int, int], end: Tuple[int, int]) -> bool:\n",
    "\n",
    "    #Determina se c'è una linea di vista diretta tra due punti senza ostacoli.\n",
    "    x0, y0 = start\n",
    "    x1, y1 = end\n",
    "    dx, dy = abs(x1 - x0), abs(y1 - y0)\n",
    "    sx, sy = 1 if x0 < x1 else -1, 1 if y0 < y1 else -1\n",
    "    err = dx - dy\n",
    "\n",
    "    while (x0, y0) != (x1, y1):\n",
    "        if is_wall(game_map[x0, y0]):\n",
    "            return False\n",
    "        e2 = 2 * err\n",
    "        if e2 > -dy:\n",
    "            err -= dy\n",
    "            x0 += sx\n",
    "        if e2 < dx:\n",
    "            err += dx\n",
    "            y0 += sy\n",
    "\n",
    "    return True\n",
    "\n",
    "# ----------------------------------------\n",
    "\n",
    "def a_star_with_monsters(game_map: np.ndarray, start: Tuple[int, int], target: Tuple[int, int], monsters: List[Tuple[int, int]], h: callable) -> List[Tuple[int, int]]:\n",
    "    open_list = PriorityQueue()\n",
    "    closed_list = set()\n",
    "    support_list = {}\n",
    "\n",
    "    starting_state_g = 0\n",
    "    starting_state_h = h(start, target)\n",
    "    starting_state_f = starting_state_g + starting_state_h\n",
    "\n",
    "    open_list.put((starting_state_f, (start, starting_state_g)))\n",
    "    support_list[start] = starting_state_g\n",
    "    parent = {start: None}\n",
    "\n",
    "    while not open_list.empty():\n",
    "        _, (current, current_cost) = open_list.get()\n",
    "        closed_list.add(current)\n",
    "\n",
    "        if current == target:\n",
    "            print(\"Target found!\")\n",
    "            path = build_path(parent, target)\n",
    "            return path\n",
    "\n",
    "        for neighbor in get_valid_moves(game_map, current):\n",
    "            if neighbor in closed_list:\n",
    "                continue\n",
    "\n",
    "            # Calcola il costo g e h\n",
    "            neighbor_g = 1 + current_cost + monster_penalty(game_map, neighbor, monsters)\n",
    "            neighbor_h = h(neighbor, target)\n",
    "            neighbor_f = neighbor_g + neighbor_h\n",
    "            parent[neighbor] = current\n",
    "\n",
    "            if neighbor in support_list:\n",
    "                if neighbor_g >= support_list[neighbor]:\n",
    "                    continue\n",
    "\n",
    "            open_list.put((neighbor_f, (neighbor, neighbor_g)))\n",
    "            support_list[neighbor] = neighbor_g\n",
    "\n",
    "    print(\"Target node not found!\")\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo Search Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from typing import Tuple, List, Dict, Set\n",
    "\n",
    "class MCTSNode:\n",
    "    def __init__(self, state, parent=None):\n",
    "        self.state = state # current state represented by the node\n",
    "        self.parent = parent # reference to the parent node\n",
    "        self.children = [] # list of child nodes\n",
    "        self.visits = 0 # number of times this node has been visited\n",
    "        self.value = 0 # cumulative reward associated with this node\n",
    "        # orthogonal moves checking\n",
    "        if parent is None:\n",
    "            self.path_to_leaf = [state]\n",
    "        else:\n",
    "            \n",
    "            px, py = parent.state\n",
    "            cx, cy = state\n",
    "            if abs(px - cx) + abs(py - cy) != 1:  # Verifica che la mossa sia di un solo passo in una direzione\n",
    "                raise ValueError(f\"Invalid move from {parent.state} to {state}\")\n",
    "            self.path_to_leaf = parent.path_to_leaf + [state]\n",
    "            \n",
    "        self.min_distance_to_target = float('inf')\n",
    "        self.visited_states = set() if parent is None else parent.visited_states.copy()\n",
    "        self.visited_states.add(state)\n",
    "        \n",
    "    def is_fully_expanded(self, game_map: np.ndarray, cached_moves: Dict[Tuple[int, int], List[Tuple[int, int]]]) -> bool:\n",
    "        if self.state not in cached_moves:\n",
    "            cached_moves[self.state] = get_valid_moves(game_map, self.state)\n",
    "        return len(self.children) == len([m for m in cached_moves[self.state] if m not in self.visited_states])\n",
    "\n",
    "    def best_child(self, exploration_weight: float = 1.0, target: Tuple[int, int] = None):\n",
    "        if not self.children:\n",
    "            return None\n",
    "            \n",
    "        scores = []\n",
    "        for child in self.children:\n",
    "            exploitation = child.value / (child.visits + 1e-6)\n",
    "            exploration = exploration_weight * np.sqrt(np.log(self.visits + 1) / (child.visits + 1e-6))\n",
    "            \n",
    "            if target:\n",
    "                current_distance = manhattan_distance(child.state, target)\n",
    "                distance_score = 1.0 / (current_distance + 1)\n",
    "                path_length_penalty = 0.2 * len(child.path_to_leaf)\n",
    "                revisit_penalty = 0.3 * len(child.visited_states.intersection(self.visited_states))\n",
    "                \n",
    "                total_score = exploitation + exploration + distance_score - path_length_penalty - revisit_penalty\n",
    "            else:\n",
    "                total_score = exploitation + exploration\n",
    "                \n",
    "            scores.append(total_score)\n",
    "            \n",
    "        return self.children[np.argmax(scores)]\n",
    "\n",
    "    def add_child(self, child_state, target: Tuple[int, int]):\n",
    "        child_node = MCTSNode(child_state, parent=self)\n",
    "        child_node.min_distance_to_target = manhattan_distance(child_state, target)\n",
    "        self.children.append(child_node)\n",
    "        return child_node\n",
    "\n",
    "def manhattan_distance(pos1: Tuple[int, int], pos2: Tuple[int, int]) -> int:\n",
    "    return abs(pos1[0] - pos2[0]) + abs(pos1[1] - pos2[1])\n",
    "\n",
    "def dynamic_reward(path_length: int, current_distance: int, initial_distance: int, \n",
    "                  best_distance: float, visited_count: int, cycle_detected: bool) -> float:\n",
    "    if current_distance == 0:  # Target reached\n",
    "        path_efficiency = max(0, 1 - (path_length / (initial_distance * 2)))\n",
    "        return 2.0 + path_efficiency  # Increased reward for reaching target\n",
    "        \n",
    "    # Heavily penalize paths with loops\n",
    "    if cycle_detected:\n",
    "        return 0.05\n",
    "        \n",
    "    progress = (initial_distance - current_distance) / initial_distance\n",
    "    length_penalty = 0.3 * (path_length / initial_distance)  # Increased length penalty\n",
    "    revisit_penalty = 0.2 * visited_count  # Increased revisit penalty\n",
    "    \n",
    "    return max(0.1, progress - length_penalty - revisit_penalty)\n",
    "\n",
    "def mcts(game_map: np.ndarray, start: Tuple[int, int], target: Tuple[int, int], \n",
    "         iterations: int = 1000, exploration_factor: float = 0.3) -> List[Tuple[int, int]]:\n",
    "    \n",
    "    root = MCTSNode(start)\n",
    "    best_path = []\n",
    "    best_distance = float('inf')\n",
    "    cached_moves = {}\n",
    "    \n",
    "    initial_distance = manhattan_distance(start, target)\n",
    "    max_reasonable_path_length = initial_distance * 3  # Increased max path length\n",
    "    \n",
    "    for iteration in range(iterations):\n",
    "        node = root\n",
    "        current_path = set([start])\n",
    "        \n",
    "        # Selection with cycle detection\n",
    "        while node.is_fully_expanded(game_map, cached_moves) and node.children:\n",
    "            node = node.best_child(exploration_factor, target)\n",
    "            if node.state in current_path:  # Cycle detected\n",
    "                break\n",
    "            current_path.add(node.state)\n",
    "            \n",
    "            if node.state == target:\n",
    "                if len(node.path_to_leaf) < best_distance:\n",
    "                    best_path = node.path_to_leaf.copy()\n",
    "                    best_distance = len(node.path_to_leaf)\n",
    "                break\n",
    "        \n",
    "        # Expansion\n",
    "        if node.state != target:\n",
    "            valid_moves = cached_moves.get(node.state) or get_valid_moves(game_map, node.state)\n",
    "            cached_moves[node.state] = valid_moves\n",
    "            unexplored = [move for move in valid_moves if move not in [child.state for child in node.children] \n",
    "                         and move not in node.visited_states]\n",
    "            \n",
    "            if unexplored:\n",
    "                # Prioritize moves that haven't been visited and are closer to target\n",
    "                new_state = min(unexplored, \n",
    "                              key=lambda pos: manhattan_distance(pos, target) + \n",
    "                                            len(current_path & {pos}) * 10)\n",
    "                node = node.add_child(new_state, target)\n",
    "                current_path.add(new_state)\n",
    "        \n",
    "        # Simulation with improved path finding\n",
    "        current_state = node.state\n",
    "        simulation_path = set(current_path)\n",
    "        simulation_steps = 0\n",
    "        cycle_detected = False\n",
    "        \n",
    "        while current_state != target and simulation_steps < max_reasonable_path_length:\n",
    "            valid_moves = cached_moves.get(current_state) or get_valid_moves(game_map, current_state)\n",
    "            cached_moves[current_state] = valid_moves\n",
    "            \n",
    "            if not valid_moves:\n",
    "                break\n",
    "                \n",
    "            # Improved move selection during simulation\n",
    "            move_scores = []\n",
    "            for move in valid_moves:\n",
    "                distance_to_target = manhattan_distance(move, target)\n",
    "                visit_penalty = 2.0 if move in simulation_path else 0.0\n",
    "                progress_score = (manhattan_distance(current_state, target) - distance_to_target)\n",
    "                \n",
    "                score = progress_score - visit_penalty + random.random() * 0.1\n",
    "                move_scores.append(score)\n",
    "            \n",
    "            next_move = valid_moves[np.argmax(move_scores)]\n",
    "            \n",
    "            if next_move in simulation_path:\n",
    "                cycle_detected = True\n",
    "                break\n",
    "                \n",
    "            current_state = next_move\n",
    "            simulation_path.add(current_state)\n",
    "            simulation_steps += 1\n",
    "        \n",
    "        # Calculate reward with improved cycle detection\n",
    "        final_distance = manhattan_distance(current_state, target)\n",
    "        reward = dynamic_reward(\n",
    "            len(simulation_path),\n",
    "            final_distance,\n",
    "            initial_distance,\n",
    "            best_distance,\n",
    "            len(simulation_path),\n",
    "            cycle_detected\n",
    "        )\n",
    "        \n",
    "        # Backpropagation\n",
    "        while node:\n",
    "            node.visits += 1\n",
    "            node.value += reward\n",
    "            node.min_distance_to_target = min(node.min_distance_to_target, final_distance)\n",
    "            node = node.parent\n",
    "            \n",
    "    return best_path if best_path and best_path[-1] == target else []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from typing import Tuple, List\n",
    "import time\n",
    "from typing import Dict, Any\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Side functions\n",
    "\n",
    "def fitness(path: List[Tuple[int, int]], target: Tuple[int, int], population=None, tabu_paths=None) -> float:\n",
    "    \"\"\"\n",
    "    Calculates fitness score for a path based on distance to target, diversity, and path quality\n",
    "    Now also considers similarity to tabu paths\n",
    "    \"\"\"\n",
    "    if not path:\n",
    "        return float('-inf')\n",
    "    \n",
    "    last_node = path[-1]\n",
    "    dist = abs(last_node[0] - target[0]) + abs(last_node[1] - target[1])\n",
    "    \n",
    "    # Calculate diversity relative to population\n",
    "    diversity_score = 0\n",
    "    if population:\n",
    "        avg_common_positions = 0\n",
    "        for other_path in population:\n",
    "            common_positions = len(set(path).intersection(set(other_path)))\n",
    "            avg_common_positions += common_positions\n",
    "        if len(population) > 0:\n",
    "            avg_common_positions /= len(population)\n",
    "            diversity_score = -avg_common_positions\n",
    "    \n",
    "    # Penalize similarity to tabu paths\n",
    "    tabu_penalty = 0\n",
    "    if tabu_paths:\n",
    "        for tabu_path in tabu_paths:\n",
    "            common_positions = len(set(path).intersection(set(tabu_path)))\n",
    "            similarity_ratio = common_positions / len(path)\n",
    "            tabu_penalty += similarity_ratio * 20  # Forte penalizzazione per similarità con percorsi tabù\n",
    "    \n",
    "    # Other calculations\n",
    "    position_counts = {}\n",
    "    for pos in path:\n",
    "        position_counts[pos] = position_counts.get(pos, 0) + 1\n",
    "    \n",
    "    repetition_penalty = sum(count - 1 for count in position_counts.values())\n",
    "    unique_positions = len(set(path))\n",
    "    progress_score = unique_positions / len(path)\n",
    "    \n",
    "    return -(dist + repetition_penalty * 2 + tabu_penalty) + (progress_score * 10) + (diversity_score * 5)\n",
    "\n",
    "def generate_random_path(game_map: np.ndarray, start: Tuple[int, int], target: Tuple[int, int], max_steps: int) -> List[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Generates a random path starting from the initial node.\n",
    "    The path develops by choosing valid moves until the target is reached or the maximum step limit is reached.\n",
    "    \"\"\"\n",
    "    path = [start]  # Start from the starting node\n",
    "    current = start\n",
    "    for _ in range(max_steps):  # Limit the length of the paths\n",
    "        neighbors = get_valid_moves(game_map, current)  # Get valid moves\n",
    "        if not neighbors:  # If there are no valid moves, end the path\n",
    "            break\n",
    "        current = random.choice(neighbors)  # Choose a random move\n",
    "        path.append(current)\n",
    "        if current == target:  # If it reaches the target, stop\n",
    "            break\n",
    "    return path\n",
    "\n",
    "def is_valid_path(path: List[Tuple[int, int]]) -> bool:\n",
    "    \"\"\"\n",
    "    Checks that the path is valid by ensuring that each step is adjacent to the previous one.\n",
    "    A step is valid if it moves by only one unit horizontally or vertically.\n",
    "    \"\"\"\n",
    "    if not path or len(path) < 2:\n",
    "        return True\n",
    "        \n",
    "    for i in range(1, len(path)):\n",
    "        prev = path[i-1]\n",
    "        curr = path[i]\n",
    "        \n",
    "        # Check that the movement is by only one unit horizontally or vertically\n",
    "        dx = abs(curr[0] - prev[0])\n",
    "        dy = abs(curr[1] - prev[1])\n",
    "        \n",
    "        # A step is valid if:\n",
    "        # - it moves by 1 horizontally and 0 vertically\n",
    "        # - it moves by 0 horizontally and 1 vertically\n",
    "        if not ((dx == 1 and dy == 0) or (dx == 0 and dy == 1)):\n",
    "            return False\n",
    "            \n",
    "    return True\n",
    "\n",
    "def crossover(parent1: List[Tuple[int, int]], parent2: List[Tuple[int, int]]) -> List[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Combines two parent paths to create a new child path,\n",
    "    ensuring that the split point produces a valid path.\n",
    "    \"\"\"\n",
    "    if len(parent1) < 3 or len(parent2) < 3:\n",
    "        return random.choice([parent1, parent2])\n",
    "    \n",
    "    max_split = min(len(parent1), len(parent2)) - 1\n",
    "    for _ in range(max_split):  # Try multiple times to find a valid split\n",
    "        split = random.randint(1, max_split)  # Choose a random split point\n",
    "        \n",
    "        # Check if the connection is valid (movement by one unit vertically or horizontally)\n",
    "        if (\n",
    "            (abs(parent1[split - 1][0] - parent2[split][0]) == 1 and parent1[split - 1][1] == parent2[split][1]) or\n",
    "            (parent1[split - 1][0] == parent2[split][0] and abs(parent1[split - 1][1] - parent2[split][1]) == 1)\n",
    "        ) and parent1[split - 1] != parent2[split]:\n",
    "            return parent1[:split] + parent2[split:]\n",
    "    \n",
    "    # If no valid split is found, return one of the parents\n",
    "    return random.choice([parent1, parent2])\n",
    "\n",
    "def mutate(path: List[Tuple[int, int]], game_map: np.ndarray, mutation_rate: float) -> List[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Applies a significant mutation with probability mutation_rate\n",
    "    \"\"\"\n",
    "    if not path or random.random() < mutation_rate:  # Do not mutate if it does not pass the probabilistic check\n",
    "        return path\n",
    "    \n",
    "    # If we pass the probability check, make a significant mutation\n",
    "    idx = random.randint(0, len(path) - 1)\n",
    "    current = path[idx]\n",
    "    new_subpath = [current]\n",
    "    \n",
    "    # Generate some random valid steps\n",
    "    for _ in range(min(5, len(path) - idx)):\n",
    "        neighbors = get_valid_moves(game_map, new_subpath[-1])\n",
    "        if not neighbors:\n",
    "            break\n",
    "        new_subpath.append(random.choice(neighbors))\n",
    "    \n",
    "    return path[:idx] + new_subpath\n",
    "\n",
    "\n",
    "# Main function\n",
    "def genetic_alg_func(game_map: np.ndarray, start: Tuple[int, int], target: Tuple[int, int], \n",
    "                    population_size: int, generations: int, mutation_rate: float, max_steps: int) -> List[List[Tuple[int, int]]]:\n",
    "    \n",
    "    population = [generate_random_path(game_map, start, target, max_steps) for _ in range(population_size)]\n",
    "    list_paths = []\n",
    "    tabu_paths = []  # Lista dei percorsi che hanno portato a stagnazione\n",
    "    \n",
    "    stagnation_counter = 0\n",
    "    best_fitness = float('-inf')\n",
    "\n",
    "    for generation in range(generations):\n",
    "        # Ordina la popolazione usando una fitness che considera i percorsi tabù\n",
    "        population.sort(key=lambda path: fitness(path, target, population, tabu_paths=tabu_paths), reverse=True)\n",
    "        \n",
    "        list_paths.append(population[0])\n",
    "        current_best_fitness = fitness(population[0], target)\n",
    "        \n",
    "        if current_best_fitness > best_fitness:\n",
    "            best_fitness = current_best_fitness\n",
    "            stagnation_counter = 0\n",
    "        else:\n",
    "            stagnation_counter += 1\n",
    "\n",
    "        # Reset totale se stagnazione\n",
    "        if stagnation_counter >= 100:\n",
    "            #print(f\"Restart totale alla generazione {generation}.\")\n",
    "            # Aggiungi il percorso corrente alla lista tabù\n",
    "            tabu_paths.append(population[0])\n",
    "            population = [generate_random_path(game_map, start, target, max_steps) for _ in range(population_size)]\n",
    "            stagnation_counter = 0\n",
    "            best_fitness = float('-inf')\n",
    "\n",
    "        # Controlla se il target è stato raggiunto\n",
    "        best_path = population[0]\n",
    "        if best_path and is_valid_path(best_path) and best_path[-1] == target:\n",
    "            print(f\"Target raggiunto in generazione {generation}\")\n",
    "            return list_paths[-1]\n",
    "\n",
    "        new_population = []\n",
    "        while len(new_population) < population_size:\n",
    "            parent1, parent2 = random.sample(population[:population_size // 2], 2)\n",
    "            child = crossover(parent1, parent2)\n",
    "            child = mutate(child, game_map, mutation_rate)\n",
    "            new_population.append(child)\n",
    "        \n",
    "        population = new_population\n",
    "\n",
    "    print(\"Target not reached after all generations.\")\n",
    "    return list_paths, generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE ACTUAL CODE TO RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import minihack\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create our environment specifying the Map and what keys we have to observe \n",
    "env = gym.make(\"MiniHack-ExploreMaze-Hard-Mapped-v0\", observation_keys=(\"chars\", \"pixel\", \"blstats\", \"message\"))\n",
    "SEED = 0\n",
    "env.seed(SEED)\n",
    "state = env.reset()\n",
    "\n",
    "coordinates = [500, 500]\n",
    "\n",
    "plt.imshow(state['pixel'][:coordinates[0], :coordinates[1]])\n",
    "\n",
    "game_map = state['chars']\n",
    "game = state['pixel']\n",
    "game_stats = state['blstats']\n",
    "game_mex = state['message']\n",
    "\n",
    "#game_map = np.array(game_map)\n",
    "\n",
    "start = get_player_location(game_map)\n",
    "target = get_target_location(game_map)\n",
    "hp = game_stats[6]\n",
    "print(\"Agent position:\", start)\n",
    "print(\"Target position:\", target)\n",
    "\n",
    "\n",
    "# Add Game Over function\n",
    "def display_game_over():\n",
    "    plt.text(0.5, 0.5, \"Game Over: You were killed by monsters!\", \n",
    "             fontsize=20, ha='center', va='center', color='red', transform=plt.gca().transAxes)\n",
    "\n",
    "# Add ictory function\n",
    "def display_victory():\n",
    "    plt.text(0.5, 0.5, \"Victory: You reached the target!\", \n",
    "             fontsize=20, ha='center', va='center', color='green', transform=plt.gca().transAxes)\n",
    "\n",
    "# Choose your algorithm\n",
    "\n",
    "#path = bfs(game_map, start, target)\n",
    "#path = dfs(game_map, start, target)\n",
    "#path = iddfs(game_map, start, target, 29)\n",
    "#path = greedy(game_map, start, target, manhattan_distance)\n",
    "#path = a_star(game_map, start, target, manhattan_distance)\n",
    "#path = theta_star(game_map, start, target, euclidean_distance)\n",
    "#path = beam_search(game_map, start, target, manhattan_distance, 5)\n",
    "#path = mcts(game_map, start, target, iterations=2000)\n",
    "#path = genetic_alg_func(game_map, start, target, 1000, 2000, 0.9, 45)\n",
    "\n",
    "actions = actions_from_path(start, path[1:])\n",
    "\n",
    "\n",
    "image = plt.imshow(game[:coordinates[0], :coordinates[1]])\n",
    "for action in actions:\n",
    "    s, _, done, _ = env.step(action)  # `done` say to us when the simulation is over\n",
    "    image.set_data(s['pixel'][:coordinates[0], :coordinates[1]])\n",
    "    \n",
    "    \n",
    "    # If the simulation is done\n",
    "    if done:\n",
    "        # If player's hp are equal to 0 it means that he is dead\n",
    "        if hp == 0: \n",
    "            display_game_over()\n",
    "            break  # Interrupt the smulation\n",
    "\n",
    "        # Else you have won    \n",
    "        display_victory()\n",
    "        break  # Interrupt the smulation\n",
    "\n",
    "\n",
    "    # Update the game visualization\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
